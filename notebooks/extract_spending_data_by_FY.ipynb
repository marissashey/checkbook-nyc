{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7faa8611-11cf-4667-a3a4-f2ff809bb931",
   "metadata": {},
   "source": [
    "# Extract Spending Data by Fiscal Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4093848b-4d72-4535-8156-fe0910e0df5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "import time\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import xml.dom.minidom\n",
    "import math\n",
    "from tqdm.notebook import tqdm\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb2f997a-ca5c-4a86-ae28-ccce257e7647",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_URL = \"https://www.checkbooknyc.com/api\"\n",
    "TEMP_XML_FILE = Path(\"tmp_latest_response.xml\")  # same temp file each time\n",
    "TIMEOUT = (300, 300) # connect_timeout, read_timeout for requests\n",
    "OUTPUT_DIR = Path(\"checkbook_data\")\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "BATCH_SIZE = 20000  # API's retrieval limit on records per request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6704becc-099f-45d0-90c4-e4e42d7526bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "main site status: 200\n"
     ]
    }
   ],
   "source": [
    "# session set up: bypass incapsula bot protection using session mgmt + browser headers\n",
    "session = requests.Session()\n",
    "HEADERS = {\n",
    "    'content-type': 'application/xml',\n",
    "    'user-agent': 'mozilla/5.0 (windows nt 10.0; win64; x64) applewebkit/537.36'\n",
    "}\n",
    "\n",
    "session.headers.update(HEADERS)\n",
    "\n",
    "# * visit main site initially *\n",
    "response = session.get('https://www.checkbooknyc.com/', timeout=TIMEOUT)\n",
    "print(f\"main site status: {response.status_code}\")\n",
    "time.sleep(2)\n",
    "\n",
    "session.headers.update({\n",
    "    'content-type': 'application/xml',\n",
    "    'referer': 'https://www.checkbooknyc.com/',\n",
    "    'origin': 'https://www.checkbooknyc.com'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8602086-cec3-4513-83fd-4272ca0c70f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a867f973-43d0-44e8-8da8-973a9839d08f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c6b2288-3cec-464f-b996-5b81697e779e",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f499b50b-914d-4cc1-9092-3044a01a0b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_xml(payload: str, verbose: bool = False) -> ET.Element:\n",
    "    response = session.post(API_URL, data=payload, headers=HEADERS, timeout=TIMEOUT)\n",
    "    if verbose: \n",
    "        print(response.text[:500])\n",
    "    response.raise_for_status()\n",
    "\n",
    "    if verbose:\n",
    "        xml_str = response.content.decode('utf-8')\n",
    "        print(xml_str)\n",
    "        \n",
    "    return ET.fromstring(response.content)\n",
    "\n",
    "def get_record_count(xml_root: ET.Element) -> int:\n",
    "    count_tag = xml_root.find(\".//result_records/record_count\")\n",
    "    return int(count_tag.text) if count_tag is not None else 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd3e120-2817-4fdc-971a-1379830046c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e53273a-086b-4233-846f-c00afe51b66e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d1e7dfd7-bb5b-422f-8f15-c090578d63b8",
   "metadata": {},
   "source": [
    "## Initial Metadata Request: Determining Pagination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12d40c5a-508b-4f6d-8d2e-c448254bbcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fiscal_year = 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "435e269d-bc19-454a-ba60-aa93de36f783",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "seed_request=f\"\"\"\n",
    "<request>\n",
    "  <type_of_data>Spending</type_of_data>\n",
    "  <records_from>1</records_from>\n",
    "  <max_records>1</max_records>\n",
    "  <search_criteria>\n",
    "   <criteria>\n",
    "      <name>fiscal_year</name>\n",
    "      <type>value</type>\n",
    "      <value>{fiscal_year}</value>\n",
    "    </criteria>\n",
    "  </search_criteria>\n",
    "  <response_columns/>\n",
    "</request>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c7b64e9-8442-469a-abf3-5b8f55d66990",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version=\"1.0\"?>\n",
      "<response>\n",
      "  <status>\n",
      "    <result>success</result>\n",
      "  </status>\n",
      "  <request_criteria>\n",
      "    <request>\n",
      "      <type_of_data>Spending</type_of_data>\n",
      "      <records_from>1</records_from>\n",
      "      <max_records>1</max_records>\n",
      "      <search_criteria>\n",
      "        <criteria>\n",
      "          <name>fiscal_year</name>\n",
      "          <type>value</type>\n",
      "          <value>2024</value>\n",
      "        </criteria>\n",
      "      </search_criteria>\n",
      "      <response_columns/>\n",
      "    </request>\n",
      "  </request_criteria>\n",
      "  <result_records>\n",
      "\n",
      "<?xml version=\"1.0\"?>\n",
      "<response>\n",
      "  <status>\n",
      "    <result>success</result>\n",
      "  </status>\n",
      "  <request_criteria>\n",
      "    <request>\n",
      "      <type_of_data>Spending</type_of_data>\n",
      "      <records_from>1</records_from>\n",
      "      <max_records>1</max_records>\n",
      "      <search_criteria>\n",
      "        <criteria>\n",
      "          <name>fiscal_year</name>\n",
      "          <type>value</type>\n",
      "          <value>2024</value>\n",
      "        </criteria>\n",
      "      </search_criteria>\n",
      "      <response_columns/>\n",
      "    </request>\n",
      "  </request_criteria>\n",
      "  <result_records>\n",
      "    <record_count>3227410</record_count>\n",
      "    <spending_transactions>\n",
      "      <transaction>\n",
      "        <agency>Police Department</agency>\n",
      "        <associated_prime_vendor>N/A</associated_prime_vendor>\n",
      "        <budget_code>0020</budget_code>\n",
      "        <capital_project/>\n",
      "        <contract_id/>\n",
      "        <mocs_registered>No</mocs_registered>\n",
      "        <contract_purpose/>\n",
      "        <check_amount>414069787.65</check_amount>\n",
      "        <department>OPERATIONS</department>\n",
      "        <document_id/>\n",
      "        <expense_category>Payroll Summary</expense_category>\n",
      "        <fiscal_year>2024</fiscal_year>\n",
      "        <industry/>\n",
      "        <issue_date>2023-07-21</issue_date>\n",
      "        <mwbe_category>Individuals and Others</mwbe_category>\n",
      "        <woman_owned_business>No </woman_owned_business>\n",
      "        <emerging_business>No </emerging_business>\n",
      "        <payee_name>OPERATIONS</payee_name>\n",
      "        <spending_category>Payroll</spending_category>\n",
      "        <sub_contract_reference_id/>\n",
      "        <sub_vendor>No</sub_vendor>\n",
      "      </transaction>\n",
      "    </spending_transactions>\n",
      "  </result_records>\n",
      "</response>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seed_root = fetch_xml(seed_request,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1049c6b6-90e1-4e41-922f-3f4223c1bcd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Seed Request Results for FY 2024\n",
      "=========================================\n",
      "Total retrievable records: 3227410\n",
      "Batches needed: 162\n",
      "\n"
     ]
    }
   ],
   "source": [
    "retrievable_records = get_record_count(seed_root)\n",
    "batches_needed = math.ceil(retrievable_records / BATCH_SIZE)\n",
    "\n",
    "print(f\"\"\"\n",
    "Seed Request Results for FY {fiscal_year}\n",
    "=========================================\n",
    "Total retrievable records: {retrievable_records}\n",
    "Batches needed: {batches_needed}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acd1d33-adcc-4b4d-8bf0-3461578ea8b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bbfdc0-9f60-426a-9562-a2f6a8f6d7d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a3c520-34c7-4bfc-ae3e-38bf3f263b52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ba4291ee-f61d-4650-baea-a7781ede001d",
   "metadata": {},
   "source": [
    "## Fetch and Save FY Spending"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e78ca5-f430-4ead-a8df-89f654e866d2",
   "metadata": {},
   "source": [
    "### Function and Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f422c61-eb78-4aab-9a52-7495718d3156",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_spending_atomic(xml_template: str, year: int, max_records_wanted: int, verbose: bool = True):\n",
    "    \"\"\"download spending data with proper range tracking and atomic saves\"\"\"\n",
    "    from datetime import datetime\n",
    "    \n",
    "    out_file = OUTPUT_DIR / f\"spending_{year}.parquet\"\n",
    "    \n",
    "    # determine starting position\n",
    "    if out_file.exists():\n",
    "        existing_df = pd.read_parquet(out_file)\n",
    "        current_count = len(existing_df)\n",
    "        next_offset = current_count + 1\n",
    "        if verbose:\n",
    "            print(f\"resuming from record {next_offset} (file has {current_count} records)\")\n",
    "    else:\n",
    "        current_count = 0\n",
    "        next_offset = 1\n",
    "        if verbose:\n",
    "            print(\"starting fresh download\")\n",
    "    \n",
    "    # calculate how many records to fetch\n",
    "    records_to_fetch = min(max_records_wanted, BATCH_SIZE)\n",
    "    timestamp = datetime.now().isoformat()\n",
    "    \n",
    "    # build xml request with proper offset\n",
    "    xml_request = xml_template.format(\n",
    "        records_from=next_offset,\n",
    "        max_records=records_to_fetch,\n",
    "        fiscal_year=year\n",
    "    )\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"requesting {records_to_fetch} records starting from {next_offset}\")\n",
    "    \n",
    "    # make api call\n",
    "    response = session.post(API_URL, data=xml_request, timeout=60)\n",
    "    \n",
    "    # validate response\n",
    "    if response.text.strip().startswith('<html'):\n",
    "        raise Exception(\"request blocked by incapsula\")\n",
    "    \n",
    "    try:\n",
    "        root = ET.fromstring(response.text.strip())\n",
    "        status = root.find('.//status/result')\n",
    "        \n",
    "        if status is None or status.text != 'success':\n",
    "            messages = root.findall('.//message/description')\n",
    "            error_msgs = [msg.text for msg in messages]\n",
    "            raise Exception(f\"api error: {error_msgs}\")\n",
    "        \n",
    "        df = parse_transactions(root)\n",
    "        \n",
    "    except ET.ParseError as e:\n",
    "        raise Exception(f\"invalid xml response: {e}\")\n",
    "    \n",
    "    # validate expected record count\n",
    "    if len(df) != records_to_fetch:\n",
    "        raise Exception(f\"expected {records_to_fetch} records, got {len(df)}\")\n",
    "    \n",
    "    # add timestamp for audit trail\n",
    "    df['time_added'] = timestamp\n",
    "    df['batch_offset'] = next_offset\n",
    "    \n",
    "    # atomic save\n",
    "    if out_file.exists():\n",
    "        # final sync check\n",
    "        existing_df = pd.read_parquet(out_file)\n",
    "        if len(existing_df) != current_count:\n",
    "            raise Exception(f\"file changed during download: expected {current_count}, found {len(existing_df)}\")\n",
    "        \n",
    "        # combine and save\n",
    "        combined_df = pd.concat([existing_df, df], ignore_index=True)\n",
    "        combined_df.to_parquet(out_file, engine=\"pyarrow\", index=False)\n",
    "    else:\n",
    "        df.to_parquet(out_file, engine=\"pyarrow\", index=False)\n",
    "    \n",
    "    if verbose:\n",
    "        total_records = current_count + len(df)\n",
    "        print(f\"saved {len(df)} records (total: {total_records})\")\n",
    "    \n",
    "    return len(df)\n",
    "\n",
    "# usage:\n",
    "xml_template = \"\"\"<request>\n",
    "  <type_of_data>Spending</type_of_data>\n",
    "  <records_from>{records_from}</records_from>\n",
    "  <max_records>{max_records}</max_records>\n",
    "  <search_criteria>\n",
    "   <criteria>\n",
    "      <name>fiscal_year</name>\n",
    "      <type>value</type>\n",
    "      <value>{fiscal_year}</value>\n",
    "    </criteria>\n",
    "  </search_criteria>\n",
    "  <response_columns>\n",
    "    <column>agency</column>\n",
    "    <column>payee_name</column>\n",
    "    <column>check_amount</column>\n",
    "    <column>issue_date</column>\n",
    "    <column>document_id</column>\n",
    "  </response_columns>\n",
    "</request>\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9026216a-a90f-444d-93c2-a2b7dcaa3154",
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm._instances.clear()\n",
    "\n",
    "def save_parquet_append(df: pd.DataFrame, out_file: Path) -> int:\n",
    "    out_file = Path(out_file)\n",
    "    if out_file.exists():\n",
    "        try:\n",
    "            pa.unregister_extension_type(\"pandas.period\")\n",
    "        except KeyError:\n",
    "            pass\n",
    "        existing_df = pd.read_parquet(out_file, engine=\"pyarrow\")\n",
    "        original_count = len(existing_df)\n",
    "        combined = pd.concat([existing_df, df], ignore_index=True)\n",
    "        deduped = combined.drop_duplicates()\n",
    "        \n",
    "        # fix: calculate actual new records added\n",
    "        final_count = len(deduped)\n",
    "        new_records_attempted = len(df)\n",
    "        \n",
    "        # net change can be negative, but \"added\" should be non-negative\n",
    "        net_change = final_count - original_count\n",
    "        actually_added = max(0, net_change)  # never negative\n",
    "        \n",
    "        deduped.to_parquet(out_file, engine=\"pyarrow\", index=False)\n",
    "        return actually_added\n",
    "    else:\n",
    "        df.to_parquet(out_file, engine=\"pyarrow\", index=False)\n",
    "        return len(df)\n",
    "\n",
    "        \n",
    "def parse_transactions(xml_root: ET.Element) -> pd.DataFrame:\n",
    "    \"\"\"convert <transaction> elements into dataframe rows\"\"\"\n",
    "    records = []\n",
    "    for txn in xml_root.findall(\".//transaction\"):\n",
    "        row = {child.tag: (child.text or \"\").strip() for child in txn}\n",
    "        records.append(row)\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "def download_all_spending(xml_template: str, year: int, total_available: int, verbose: bool = True):\n",
    "    \"\"\"download all available spending records for given year\"\"\"\n",
    "\n",
    "    out_file = OUTPUT_DIR / f\"spending_{year}.parquet\"\n",
    "    \n",
    "    # check current progress\n",
    "    if out_file.exists():\n",
    "        existing_df = pd.read_parquet(out_file)\n",
    "        records_downloaded = len(existing_df)\n",
    "    else:\n",
    "        records_downloaded = 0\n",
    "    \n",
    "    records_remaining = total_available - records_downloaded\n",
    "    \n",
    "    if records_remaining <= 0:\n",
    "        if verbose:\n",
    "            print(f\"download already complete: {records_downloaded:,} records\")\n",
    "        return\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"downloading {records_remaining:,} remaining records (total: {total_available:,})\")\n",
    "    \n",
    "    with tqdm(total=records_remaining, desc=f\"FY{year}\", unit=\"records\") as pbar:\n",
    "        while records_remaining > 0:\n",
    "            # calculate batch size for this request\n",
    "            batch_size = min(BATCH_SIZE, records_remaining)\n",
    "            \n",
    "            try:\n",
    "                # download one batch\n",
    "                records_saved = download_spending_atomic(xml_template, year, batch_size, verbose=False)\n",
    "                \n",
    "                # update progress\n",
    "                records_remaining -= records_saved\n",
    "                pbar.update(records_saved)\n",
    "                \n",
    "                if verbose:\n",
    "                    total_now = total_available - records_remaining\n",
    "                    tqdm.write(f\"batch complete: {records_saved:,} saved, {total_now:,} total, {records_remaining:,} remaining\")\n",
    "                \n",
    "                # rate limiting - api requires 1 request per second\n",
    "                time.sleep(1.1)\n",
    "                \n",
    "            except Exception as e:\n",
    "                tqdm.write(f\"batch failed: {e}\")\n",
    "                tqdm.write(\"retrying in 5 seconds...\")\n",
    "                time.sleep(5)\n",
    "                # continue loop without updating counters - will retry same batch\n",
    "    \n",
    "    if verbose:\n",
    "        final_df = pd.read_parquet(out_file)\n",
    "        print(f\"download complete: {len(final_df):,} total records saved\")\n",
    "\n",
    "# usage:\n",
    "xml_template = \"\"\"<request>\n",
    "  <type_of_data>Spending</type_of_data>\n",
    "  <records_from>{records_from}</records_from>\n",
    "  <max_records>{max_records}</max_records>\n",
    "  <search_criteria>\n",
    "   <criteria>\n",
    "      <name>fiscal_year</name>\n",
    "      <type>value</type>\n",
    "      <value>{fiscal_year}</value>\n",
    "    </criteria>\n",
    "  </search_criteria>\n",
    "  <response_columns>\n",
    "    <column>agency</column>\n",
    "    <column>payee_name</column>\n",
    "    <column>check_amount</column>\n",
    "    <column>issue_date</column>\n",
    "    <column>document_id</column>\n",
    "    <column>spending_category</column>\n",
    "    <column>department</column>\n",
    "    <column>fiscal_year</column>\n",
    "  </response_columns>\n",
    "</request>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95359586-4269-47eb-babd-58afb2a959c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "270eba9b-47ec-438d-af89-820dc2bd9579",
   "metadata": {},
   "source": [
    "### Function Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0099efd4-5ac5-477b-9da2-dfb5ae8e492f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading 3,227,410 remaining records (total: 3,227,410)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ee39a29d3d6485aabc96dca2180cf17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FY2024:   0%|                                                      | 0/3227410 [00:00<?, ?records/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch complete: 20,000 saved, 20,000 total, 3,207,410 remaining\n",
      "batch complete: 20,000 saved, 40,000 total, 3,187,410 remaining\n",
      "batch complete: 20,000 saved, 60,000 total, 3,167,410 remaining\n",
      "batch complete: 20,000 saved, 80,000 total, 3,147,410 remaining\n",
      "batch complete: 20,000 saved, 100,000 total, 3,127,410 remaining\n",
      "batch complete: 20,000 saved, 120,000 total, 3,107,410 remaining\n",
      "batch complete: 20,000 saved, 140,000 total, 3,087,410 remaining\n",
      "batch complete: 20,000 saved, 160,000 total, 3,067,410 remaining\n",
      "batch complete: 20,000 saved, 180,000 total, 3,047,410 remaining\n",
      "batch complete: 20,000 saved, 200,000 total, 3,027,410 remaining\n",
      "batch complete: 20,000 saved, 220,000 total, 3,007,410 remaining\n",
      "batch complete: 20,000 saved, 240,000 total, 2,987,410 remaining\n",
      "batch complete: 20,000 saved, 260,000 total, 2,967,410 remaining\n",
      "batch complete: 20,000 saved, 280,000 total, 2,947,410 remaining\n",
      "batch complete: 20,000 saved, 300,000 total, 2,927,410 remaining\n",
      "batch complete: 20,000 saved, 320,000 total, 2,907,410 remaining\n",
      "batch complete: 20,000 saved, 340,000 total, 2,887,410 remaining\n",
      "batch complete: 20,000 saved, 360,000 total, 2,867,410 remaining\n",
      "batch complete: 20,000 saved, 380,000 total, 2,847,410 remaining\n",
      "batch complete: 20,000 saved, 400,000 total, 2,827,410 remaining\n",
      "batch complete: 20,000 saved, 420,000 total, 2,807,410 remaining\n",
      "batch complete: 20,000 saved, 440,000 total, 2,787,410 remaining\n",
      "batch complete: 20,000 saved, 460,000 total, 2,767,410 remaining\n",
      "batch complete: 20,000 saved, 480,000 total, 2,747,410 remaining\n",
      "batch complete: 20,000 saved, 500,000 total, 2,727,410 remaining\n",
      "batch complete: 20,000 saved, 520,000 total, 2,707,410 remaining\n",
      "batch complete: 20,000 saved, 540,000 total, 2,687,410 remaining\n",
      "batch complete: 20,000 saved, 560,000 total, 2,667,410 remaining\n",
      "batch complete: 20,000 saved, 580,000 total, 2,647,410 remaining\n",
      "batch complete: 20,000 saved, 600,000 total, 2,627,410 remaining\n",
      "batch complete: 20,000 saved, 620,000 total, 2,607,410 remaining\n",
      "batch complete: 20,000 saved, 640,000 total, 2,587,410 remaining\n",
      "batch complete: 20,000 saved, 660,000 total, 2,567,410 remaining\n",
      "batch complete: 20,000 saved, 680,000 total, 2,547,410 remaining\n",
      "batch complete: 20,000 saved, 700,000 total, 2,527,410 remaining\n",
      "batch complete: 20,000 saved, 720,000 total, 2,507,410 remaining\n",
      "batch complete: 20,000 saved, 740,000 total, 2,487,410 remaining\n",
      "batch complete: 20,000 saved, 760,000 total, 2,467,410 remaining\n",
      "batch complete: 20,000 saved, 780,000 total, 2,447,410 remaining\n",
      "batch complete: 20,000 saved, 800,000 total, 2,427,410 remaining\n",
      "batch complete: 20,000 saved, 820,000 total, 2,407,410 remaining\n",
      "batch complete: 20,000 saved, 840,000 total, 2,387,410 remaining\n",
      "batch complete: 20,000 saved, 860,000 total, 2,367,410 remaining\n",
      "batch complete: 20,000 saved, 880,000 total, 2,347,410 remaining\n",
      "batch complete: 20,000 saved, 900,000 total, 2,327,410 remaining\n",
      "batch complete: 20,000 saved, 920,000 total, 2,307,410 remaining\n",
      "batch complete: 20,000 saved, 940,000 total, 2,287,410 remaining\n",
      "batch complete: 20,000 saved, 960,000 total, 2,267,410 remaining\n",
      "batch complete: 20,000 saved, 980,000 total, 2,247,410 remaining\n",
      "batch complete: 20,000 saved, 1,000,000 total, 2,227,410 remaining\n",
      "batch complete: 20,000 saved, 1,020,000 total, 2,207,410 remaining\n",
      "batch complete: 20,000 saved, 1,040,000 total, 2,187,410 remaining\n",
      "batch complete: 20,000 saved, 1,060,000 total, 2,167,410 remaining\n",
      "batch complete: 20,000 saved, 1,080,000 total, 2,147,410 remaining\n",
      "batch complete: 20,000 saved, 1,100,000 total, 2,127,410 remaining\n",
      "batch complete: 20,000 saved, 1,120,000 total, 2,107,410 remaining\n",
      "batch complete: 20,000 saved, 1,140,000 total, 2,087,410 remaining\n",
      "batch complete: 20,000 saved, 1,160,000 total, 2,067,410 remaining\n",
      "batch complete: 20,000 saved, 1,180,000 total, 2,047,410 remaining\n",
      "batch complete: 20,000 saved, 1,200,000 total, 2,027,410 remaining\n",
      "batch complete: 20,000 saved, 1,220,000 total, 2,007,410 remaining\n",
      "batch complete: 20,000 saved, 1,240,000 total, 1,987,410 remaining\n",
      "batch complete: 20,000 saved, 1,260,000 total, 1,967,410 remaining\n",
      "batch complete: 20,000 saved, 1,280,000 total, 1,947,410 remaining\n",
      "batch complete: 20,000 saved, 1,300,000 total, 1,927,410 remaining\n",
      "batch complete: 20,000 saved, 1,320,000 total, 1,907,410 remaining\n",
      "batch complete: 20,000 saved, 1,340,000 total, 1,887,410 remaining\n",
      "batch complete: 20,000 saved, 1,360,000 total, 1,867,410 remaining\n",
      "batch complete: 20,000 saved, 1,380,000 total, 1,847,410 remaining\n",
      "batch complete: 20,000 saved, 1,400,000 total, 1,827,410 remaining\n",
      "batch complete: 20,000 saved, 1,420,000 total, 1,807,410 remaining\n",
      "batch complete: 20,000 saved, 1,440,000 total, 1,787,410 remaining\n",
      "batch complete: 20,000 saved, 1,460,000 total, 1,767,410 remaining\n",
      "batch complete: 20,000 saved, 1,480,000 total, 1,747,410 remaining\n",
      "batch complete: 20,000 saved, 1,500,000 total, 1,727,410 remaining\n",
      "batch complete: 20,000 saved, 1,520,000 total, 1,707,410 remaining\n",
      "batch complete: 20,000 saved, 1,540,000 total, 1,687,410 remaining\n",
      "batch complete: 20,000 saved, 1,560,000 total, 1,667,410 remaining\n",
      "batch complete: 20,000 saved, 1,580,000 total, 1,647,410 remaining\n",
      "batch complete: 20,000 saved, 1,600,000 total, 1,627,410 remaining\n",
      "batch complete: 20,000 saved, 1,620,000 total, 1,607,410 remaining\n",
      "batch complete: 20,000 saved, 1,640,000 total, 1,587,410 remaining\n",
      "batch complete: 20,000 saved, 1,660,000 total, 1,567,410 remaining\n",
      "batch complete: 20,000 saved, 1,680,000 total, 1,547,410 remaining\n",
      "batch complete: 20,000 saved, 1,700,000 total, 1,527,410 remaining\n",
      "batch complete: 20,000 saved, 1,720,000 total, 1,507,410 remaining\n",
      "batch complete: 20,000 saved, 1,740,000 total, 1,487,410 remaining\n",
      "batch complete: 20,000 saved, 1,760,000 total, 1,467,410 remaining\n",
      "batch complete: 20,000 saved, 1,780,000 total, 1,447,410 remaining\n",
      "batch complete: 20,000 saved, 1,800,000 total, 1,427,410 remaining\n",
      "batch complete: 20,000 saved, 1,820,000 total, 1,407,410 remaining\n",
      "batch complete: 20,000 saved, 1,840,000 total, 1,387,410 remaining\n",
      "batch complete: 20,000 saved, 1,860,000 total, 1,367,410 remaining\n",
      "batch complete: 20,000 saved, 1,880,000 total, 1,347,410 remaining\n",
      "batch complete: 20,000 saved, 1,900,000 total, 1,327,410 remaining\n",
      "batch complete: 20,000 saved, 1,920,000 total, 1,307,410 remaining\n",
      "batch complete: 20,000 saved, 1,940,000 total, 1,287,410 remaining\n",
      "batch complete: 20,000 saved, 1,960,000 total, 1,267,410 remaining\n",
      "batch complete: 20,000 saved, 1,980,000 total, 1,247,410 remaining\n",
      "batch complete: 20,000 saved, 2,000,000 total, 1,227,410 remaining\n",
      "batch complete: 20,000 saved, 2,020,000 total, 1,207,410 remaining\n",
      "batch complete: 20,000 saved, 2,040,000 total, 1,187,410 remaining\n",
      "batch complete: 20,000 saved, 2,060,000 total, 1,167,410 remaining\n",
      "batch complete: 20,000 saved, 2,080,000 total, 1,147,410 remaining\n",
      "batch complete: 20,000 saved, 2,100,000 total, 1,127,410 remaining\n",
      "batch complete: 20,000 saved, 2,120,000 total, 1,107,410 remaining\n",
      "batch complete: 20,000 saved, 2,140,000 total, 1,087,410 remaining\n",
      "batch complete: 20,000 saved, 2,160,000 total, 1,067,410 remaining\n",
      "batch complete: 20,000 saved, 2,180,000 total, 1,047,410 remaining\n",
      "batch complete: 20,000 saved, 2,200,000 total, 1,027,410 remaining\n",
      "batch complete: 20,000 saved, 2,220,000 total, 1,007,410 remaining\n",
      "batch complete: 20,000 saved, 2,240,000 total, 987,410 remaining\n",
      "batch complete: 20,000 saved, 2,260,000 total, 967,410 remaining\n",
      "batch complete: 20,000 saved, 2,280,000 total, 947,410 remaining\n",
      "batch complete: 20,000 saved, 2,300,000 total, 927,410 remaining\n",
      "batch complete: 20,000 saved, 2,320,000 total, 907,410 remaining\n",
      "batch complete: 20,000 saved, 2,340,000 total, 887,410 remaining\n",
      "batch complete: 20,000 saved, 2,360,000 total, 867,410 remaining\n",
      "batch complete: 20,000 saved, 2,380,000 total, 847,410 remaining\n",
      "batch complete: 20,000 saved, 2,400,000 total, 827,410 remaining\n",
      "batch complete: 20,000 saved, 2,420,000 total, 807,410 remaining\n",
      "batch complete: 20,000 saved, 2,440,000 total, 787,410 remaining\n",
      "batch complete: 20,000 saved, 2,460,000 total, 767,410 remaining\n",
      "batch complete: 20,000 saved, 2,480,000 total, 747,410 remaining\n",
      "batch complete: 20,000 saved, 2,500,000 total, 727,410 remaining\n",
      "batch complete: 20,000 saved, 2,520,000 total, 707,410 remaining\n",
      "batch complete: 20,000 saved, 2,540,000 total, 687,410 remaining\n",
      "batch complete: 20,000 saved, 2,560,000 total, 667,410 remaining\n",
      "batch complete: 20,000 saved, 2,580,000 total, 647,410 remaining\n",
      "batch complete: 20,000 saved, 2,600,000 total, 627,410 remaining\n",
      "batch complete: 20,000 saved, 2,620,000 total, 607,410 remaining\n",
      "batch complete: 20,000 saved, 2,640,000 total, 587,410 remaining\n",
      "batch complete: 20,000 saved, 2,660,000 total, 567,410 remaining\n",
      "batch complete: 20,000 saved, 2,680,000 total, 547,410 remaining\n",
      "batch complete: 20,000 saved, 2,700,000 total, 527,410 remaining\n",
      "batch complete: 20,000 saved, 2,720,000 total, 507,410 remaining\n",
      "batch complete: 20,000 saved, 2,740,000 total, 487,410 remaining\n",
      "batch complete: 20,000 saved, 2,760,000 total, 467,410 remaining\n",
      "batch complete: 20,000 saved, 2,780,000 total, 447,410 remaining\n",
      "batch complete: 20,000 saved, 2,800,000 total, 427,410 remaining\n",
      "batch complete: 20,000 saved, 2,820,000 total, 407,410 remaining\n",
      "batch complete: 20,000 saved, 2,840,000 total, 387,410 remaining\n",
      "batch complete: 20,000 saved, 2,860,000 total, 367,410 remaining\n",
      "batch complete: 20,000 saved, 2,880,000 total, 347,410 remaining\n",
      "batch complete: 20,000 saved, 2,900,000 total, 327,410 remaining\n",
      "batch complete: 20,000 saved, 2,920,000 total, 307,410 remaining\n",
      "batch complete: 20,000 saved, 2,940,000 total, 287,410 remaining\n",
      "batch complete: 20,000 saved, 2,960,000 total, 267,410 remaining\n",
      "batch complete: 20,000 saved, 2,980,000 total, 247,410 remaining\n",
      "batch complete: 20,000 saved, 3,000,000 total, 227,410 remaining\n",
      "batch complete: 20,000 saved, 3,020,000 total, 207,410 remaining\n",
      "batch complete: 20,000 saved, 3,040,000 total, 187,410 remaining\n",
      "batch complete: 20,000 saved, 3,060,000 total, 167,410 remaining\n",
      "batch complete: 20,000 saved, 3,080,000 total, 147,410 remaining\n",
      "batch complete: 20,000 saved, 3,100,000 total, 127,410 remaining\n",
      "batch complete: 20,000 saved, 3,120,000 total, 107,410 remaining\n",
      "batch complete: 20,000 saved, 3,140,000 total, 87,410 remaining\n",
      "batch complete: 20,000 saved, 3,160,000 total, 67,410 remaining\n",
      "batch complete: 20,000 saved, 3,180,000 total, 47,410 remaining\n",
      "batch complete: 20,000 saved, 3,200,000 total, 27,410 remaining\n",
      "batch complete: 20,000 saved, 3,220,000 total, 7,410 remaining\n",
      "batch complete: 7,410 saved, 3,227,410 total, 0 remaining\n",
      "download complete: 3,227,410 total records saved\n"
     ]
    }
   ],
   "source": [
    "# download all records\n",
    "download_all_spending(xml_template, fiscal_year, retrievable_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eec9957-51fc-493f-ad13-c878a43eaef6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec104a1-b154-45c1-86ad-3de8af08a21c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fa6af038-d164-4d9e-8aa3-c467fd4b3697",
   "metadata": {},
   "source": [
    "## Peek in Parquet Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ad0c0ea-ecca-4f5b-8c9a-f0c9c6cc4a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    agency  check_amount                      department  \\\n",
      "0        Police Department  414069787.65                      OPERATIONS   \n",
      "1  Department of Education  155467775.81  GE INSTR & SCH LEADERSHIP - PS   \n",
      "2  Department of Education  146837179.49  GE INSTR & SCH LEADERSHIP - PS   \n",
      "3  Department of Education  144663291.19  GE INSTR & SCH LEADERSHIP - PS   \n",
      "4  Department of Education  144085954.76  GE INSTR & SCH LEADERSHIP - PS   \n",
      "\n",
      "  document_id fiscal_year  issue_date                      payee_name  \\\n",
      "0                    2024  2023-07-21                      OPERATIONS   \n",
      "1                    2024  2023-09-29  GE INSTR & SCH LEADERSHIP - PS   \n",
      "2                    2024  2024-02-15  GE INSTR & SCH LEADERSHIP - PS   \n",
      "3                    2024  2024-02-29  GE INSTR & SCH LEADERSHIP - PS   \n",
      "4                    2024  2023-12-29  GE INSTR & SCH LEADERSHIP - PS   \n",
      "\n",
      "  spending_category                  time_added  batch_offset  \n",
      "0           Payroll  2025-08-23T02:42:02.391186             1  \n",
      "1           Payroll  2025-08-23T02:42:02.391186             1  \n",
      "2           Payroll  2025-08-23T02:42:02.391186             1  \n",
      "3           Payroll  2025-08-23T02:42:02.391186             1  \n",
      "4           Payroll  2025-08-23T02:42:02.391186             1  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3227410 entries, 0 to 3227409\n",
      "Data columns (total 10 columns):\n",
      " #   Column             Dtype \n",
      "---  ------             ----- \n",
      " 0   agency             object\n",
      " 1   check_amount       object\n",
      " 2   department         object\n",
      " 3   document_id        object\n",
      " 4   fiscal_year        object\n",
      " 5   issue_date         object\n",
      " 6   payee_name         object\n",
      " 7   spending_category  object\n",
      " 8   time_added         object\n",
      " 9   batch_offset       int64 \n",
      "dtypes: int64(1), object(9)\n",
      "memory usage: 246.2+ MB\n",
      "None\n",
      "Index(['agency', 'check_amount', 'department', 'document_id', 'fiscal_year',\n",
      "       'issue_date', 'payee_name', 'spending_category', 'time_added',\n",
      "       'batch_offset'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "file_path = \"checkbook_data/spending_2024.parquet\"\n",
    "df = pd.read_parquet(file_path, engine=\"pyarrow\") \n",
    "\n",
    "print(df.head())\n",
    "\n",
    "print(df.info())\n",
    "\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ded62e5-593c-48a9-b8bb-45f4d0148e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file exists: 3227410 records\n",
      "xml files: 6\n"
     ]
    }
   ],
   "source": [
    "# check what actually got saved\n",
    "out_file = OUTPUT_DIR / f\"spending_{fiscal_year}.parquet\"\n",
    "if out_file.exists():\n",
    "    df_check = pd.read_parquet(out_file)\n",
    "    print(f\"file exists: {len(df_check)} records\")\n",
    "else:\n",
    "    print(\"no file created\")\n",
    "    \n",
    "# check if xml was saved\n",
    "xml_files = list(OUTPUT_DIR.glob(\"raw_FY*.xml\"))\n",
    "print(f\"xml files: {len(xml_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689b8155-c2fe-4463-9011-31990916121d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb4e518-30f8-4582-b5b3-37e92ebbd5c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b12d14a-449d-47ef-9460-6273f71aa348",
   "metadata": {},
   "source": [
    "##  API Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f001908-0e6d-4c82-aa7a-2da13f9a25f2",
   "metadata": {},
   "source": [
    "https://www.checkbooknyc.com/spending-api\n",
    "\n",
    "- retrieval limit: 20K records per call\n",
    "- FY25: 3.2M transactions \n",
    "- to retrieve all: stagger `records_from` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d8a7ad-4e43-45a8-80ca-ffc2455ab0a8",
   "metadata": {},
   "source": [
    "3,157,063 transactions <- as of 8/22 from data feeds https://www.checkbooknyc.com/data-feeds "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96b1500-e99b-4093-a91e-7092005047d2",
   "metadata": {},
   "source": [
    "##### XML request:\n",
    "- global params: `type_of_data`, `records_from`, `max_records`\n",
    "- filters: put in `<search_criteria>`\n",
    "- requested columns: put in `<response_columns>`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206d0c87-339a-4335-bb48-3f9b75bb9a82",
   "metadata": {},
   "source": [
    "##### XML response: \n",
    "- `<search_criteria>`: echoes request xml\n",
    "- `<result_records>`: current result batch based on `records_from` and `max_records`\n",
    "- `<record_count>`: TOTAL rows\n",
    "- `<messages>`: errors + status info\n",
    "- `<status>`: success/failure of request"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b439510-0065-4afe-865b-6668235501d3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "##### prossibly outdated thread on rate limits\n",
    "https://groups.google.com/g/checkbooknyc/c/hgU1niDG00Y?pli=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fba19a-6651-4281-9815-517875ccf9b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7acd8f6-4978-4fbf-9583-bbaff45101a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2566b5c7-023e-4212-a880-5544f5edbc22",
   "metadata": {},
   "source": [
    "## Technical Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290ff2c9-8600-4549-b9e3-d9976ef52feb",
   "metadata": {},
   "source": [
    "### api integration:\n",
    "- bypass incapsula bot protection using session mgmt + browser headers\n",
    "- learn xml format structure requirements of checkbooknyc api\n",
    "- debug XML templating issues betewen f-strings vs `.format()`\n",
    "\n",
    "### pagination / data integrity:\n",
    "- **problem**: deduplication approach failed - legitimate different records marked as duplicates\n",
    "- **root cause**: overlapping requests (requesting records 1-20000 when file had 1-19815)\n",
    "- **solution**: range tracking with atomic saves eliminates deduplication need\n",
    "\n",
    "### download architecture:\n",
    "- resumable downloads using file length to calculate next offset\n",
    "- atomic batch operations ensure data consistency if interrupted\n",
    "- complying with rate limiting + error handling with auto retry\n",
    "- progress tracking for slo downloads (e.g., full FY)\n",
    "\n",
    "### key insights\n",
    "- solve api pagination problem at the request level (proper offsets) instead of data level (deduplication).\n",
    "- separate concerns: overlapping requests vs. data consistency\n",
    "- well-structured batch system with proper offsets -> remarkably less data mucking / data handling complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b644f0f-24e6-45fc-8ba7-dd1bf89b2da9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d83dc7-45c0-4fa7-ba7d-5673f8b27f9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
